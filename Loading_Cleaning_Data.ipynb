{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "import urllib.request\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pymysql\n",
    "from io import BufferedReader\n",
    "\n",
    "# THIS CODE NEEDS TO BE RUN BEFORE MAKING THE SQL CONNECTION\n",
    "\n",
    "pymysql.converters.encoders[np.float64] = pymysql.converters.escape_float\n",
    "pymysql.converters.conversions = pymysql.converters.encoders.copy()\n",
    "pymysql.converters.conversions.update(pymysql.converters.decoders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the csv(format 1) Data from the API, Annual Activity\n",
    "\n",
    "def get_data_In_Csv(name,list_col):\n",
    "        dfsym = pd.read_json (r'symbol_few.json',orient='records')\n",
    "        companies = dfsym['symbol']\n",
    "        url = stock_dict[name]\n",
    "        newdata = pd.DataFrame(columns=list_col)\n",
    "        def fetch_data(newurl):\n",
    "                try:\n",
    "                    data = pd.read_csv(newurl,error_bad_lines=False)                   \n",
    "                    return data\n",
    "                except:\n",
    "                    print('Failed loading...trying again')\n",
    "                    return fetch_data(newurl)\n",
    "        for x in companies:\n",
    "            newurl = url.replace('code',x)\n",
    "            data = fetch_data(newurl)\n",
    "            print(data)\n",
    "            colname = data.columns\n",
    "            nextnum = 0\n",
    "            for j in range (1,data.shape[1]):\n",
    "                k=newdata.shape[0]\n",
    "                values = data[data.columns[j]]\n",
    "                for i in range(len(values)+2):\n",
    "\n",
    "                    if (i==0):\n",
    "                        newdata.loc[k,list_col[0]] = x\n",
    "                    if (i==1):                    \n",
    "                        newdata.loc[k,list_col[1]] = colname[nextnum+1] \n",
    "                        nextnum=nextnum+1\n",
    "                    if(i>1):\n",
    "                        newdata.loc[k,list_col[i]] = values[i-2]\n",
    "        \n",
    "        saveToSQL(name,newdata,'replace')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the csv(format 2) Data from the API, Annual Activity\n",
    "\n",
    "def get_data_In_Csv2(name,list_col):\n",
    "        dfsym = pd.read_json (r'symbol_selected.json',orient='records')\n",
    "        companies = dfsym['symbol']\n",
    "        url = stock_dict[name]\n",
    "        newdata = pd.DataFrame(columns=list_col)         \n",
    "        for x in companies:\n",
    "            print(x)\n",
    "            newurl = url.replace('code',x)\n",
    "            try:\n",
    "                data = pd.read_csv(newurl,error_bad_lines=False)\n",
    "                colname = newdata.columns\n",
    "                if (newdata.shape[0] ==0):\n",
    "                    newdata['STOCK_TIKR'] = \"\"\n",
    "                rowcount = newdata.shape[0]\n",
    "                newdata = newdata.append(data,ignore_index= True)\n",
    "                currrow = rowcount+len(data)\n",
    "                newdata.iloc[rowcount:currrow,newdata.columns.get_loc('STOCK_TIKR')]=x\n",
    "            except:\n",
    "                # ignore bad lines\n",
    "                pass    \n",
    "        saveToSQL(name,newdata,'replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the data to MySQL\n",
    "\n",
    "def saveToSQL(tablename,dataframe,todo):\n",
    "    from sqlalchemy import create_engine\n",
    "    engine = create_engine('mysql+pymysql://nativeuser:password@localhost/automatic_portfolio_creation')\n",
    "    dataframe.to_sql(tablename, con = engine, if_exists=todo, chunksize = 500)\n",
    "    print('Data has been loaded to',tablename,'table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to create tables for different financial statements to downloan from API\n",
    "\n",
    "list_col = ['STOCK_TIKR','DATE_YEAR','DEPRECIATION_AMORTIZATION','STOCK_BASED_COMPENSATION','OPERATING_CASH_FLOW','CAPITAL_EXPENDITURE',\n",
    "             'ACQUISITIONS_DISPOSALS','INVESTMENT_PURCHASES_SALES','INVESTING_CASH_FLOW','ISSUANCE_DEBT_REPAYMENT',\n",
    "             'ISSUANCE_SHARES_BUYBACKS','DIVIDEND_PAYMENTS','FINANCING_CASH_FLOW','EFFECT_FOREX_CHANGES',\n",
    "              'NET_CASH_FLOW','FREE_CASH_FLOW','NET_CASH_MARKET_CAP']\n",
    "\n",
    "list_col_balance_sheet = ['STOCK_TIKR','DATE_YEAR','CASH_CASH_EQUIVALENT','SHORT_TERM_INVESTMNET','CASH_SHORT_TERM_INVST','RECEIVABLES',\n",
    "                          'INVENTORIES','TOTAL_CURRENT_ASSETS','GOODWILL_INTANGIBLE_ASSETS','LONG_TERM_INVESTMENTS', 'TAX_ASSETS',\n",
    "                          'TOTAL_NON_CURR_ASSETS','TOTAL_ASSETS','PAYABLES','SHORT_TERM_DEBT','TOTAL_CURR_LIABILITIES','LONG_TERM_DEBT',\n",
    "                          'TOTAL_DEBT','DEFERRED_REVENUE','TAX_LIABILITIES','DEPOSIT_LIABILITIES','TOTAL_NON_CURR_LIABILITIES','TOTAL_LIABILITIES',\n",
    "                          'OTHER_COMPREHENSIVE_INCOME','RETAINED_EARNINGS_DEFICIT','TOTAL_SHAREHOLDERS_EQUITY','INVESTMENTS','NET_DEBT','OTHER_ASSETS','OTHER_LIABILITIES']\n",
    "\n",
    "list_col_income = ['STOCK_TIKR','DATE_YEAR','REVENUE','REVENUE_GROWTH','COST_OF_REVENUE','GROSS_PROFIT','RND_EXPENSES',\n",
    "             'SGNA_EXPENSES','OPERATING_EXPENSES','OPERATING_INCOME','INTEREST_EXPENSE',\n",
    "             'EARNINGS_BEFORE_TAX','INCOME_TAX_EXPENSE','NET_INC_NON_CONTROLLING_INT','NET_INC_DISCONTINUED_OPS',\n",
    "              'NET_INCOME','PREFERRED_DIVIDENDS','NET_INCOME_COM','EPS','EPS_DILUTED','WEIGHTED_AVERAGE_SHS_OUT','WEIGHTED_AVERAGE_SHS_OUT_DIL',\n",
    "              'DIVIDEND_PER_SHARE','GROSS_MARGIN','EBITDA_MARGIN','EBIT_MARGIN','PROFIT_MARGIN','FCF_MARGIN','EBITDA','EBIT','CONSOLIDATED_INCOME',\n",
    "                'EARNINGS_BEFORE_MARGIN','NET_PROFIT_MARGIN']\n",
    "list_col_hist_prices = ['STOCK_TIKR','Date','Close']\n",
    "list_col_annual_change = ['STOCK_TIKR','Date','Close']\n",
    "\n",
    "stock_dict = {'cash_flow_stmt':'https://financialmodelingprep.com/api/v3/financials/cash-flow-statement/code?datatype=csv',\n",
    "              'income_statement':'https://financialmodelingprep.com/api/v3/financials/income-statement/code?datatype=csv',\n",
    "              'balance_sheet' : 'https://financialmodelingprep.com/api/v3/financials/balance-sheet-statement/code?datatype=csv',\n",
    "              'bal_sheet1' : 'https://financialmodelingprep.com/api/v3/financials/balance-sheet-statement/code?datatype=csv',\n",
    "              'hist_prices' : 'https://www.quandl.com/api/v3/datasets/WIKI/code/data.csv?column_index=4&start_date=2009-01-01&end_date=2019-10-30&order=asc&collapse=monthly',\n",
    "              'hist_annual_change' : 'https://www.quandl.com/api/v3/datasets/WIKI/code/data.csv?column_index=4&start_date=2009-01-01&end_date=2019-11-30&order=asc&collapse=annual&transform=rdiff'\n",
    "              }\n",
    "              \n",
    "\n",
    "# Calling the functions to load the data from API - Annual Activity.\n",
    "\n",
    "# get_data_In_Csv('cash_flow_stmt',list_col)\n",
    "# get_data_In_Csv('income_statement',list_col_income)\n",
    "#get_data_In_Csv('bal_sheet1',list_col_balance_sheet)\n",
    "#get_data_In_Csv2('hist_prices',list_col_hist_prices)\n",
    "get_data_In_Csv2('hist_annual_change',list_col_annual_change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to load key financial ratios  - 1\n",
    "\n",
    "import urllib.request, json\n",
    "import pandas as pd\n",
    "from pandas.io.json import json_normalize\n",
    "\n",
    "dfsym = pd.read_json (r'symbol_selected.json',orient='records')\n",
    "\n",
    "dfdata = pd.DataFrame()\n",
    "\n",
    "rowcount = 0\n",
    "companies = dfsym['symbol']\n",
    "\n",
    "nodatalist =[]\n",
    "url = 'https://financialmodelingprep.com/api/v3/company-key-metrics/code'\n",
    "for x in companies:\n",
    "    print(x)\n",
    "    newurl = url.replace('code',x)\n",
    "    mydata=[]\n",
    "    with urllib.request.urlopen(newurl) as url_fin:\n",
    "        data = json.loads(url_fin.read().decode())\n",
    "        if (data != {} ):\n",
    "            mydata = data['metrics']\n",
    "            if (dfdata.shape[0] ==0):\n",
    "                dfdata['STK_TKR'] = \"\"\n",
    "        \n",
    "            rowcount = dfdata.shape[0]\n",
    "            dfdata = dfdata.append(mydata)\n",
    "            currrow = rowcount+len(mydata)\n",
    "            dfdata.iloc[rowcount:currrow,dfdata.columns.get_loc('STK_TKR')]=x\n",
    "        else:\n",
    "            nodatalist.append(x)\n",
    "       \n",
    "    \n",
    "print('Companies that do not have data',nodatalist)\n",
    "\n",
    "dfdata.columns = ['Average_Inventory','Average_Payables','Average_Receivables','Book_Value_per_Share','Capex_per_Share','Capex_to_Depreciation',\n",
    "'Capex_to_Operating_Cash_Flow','Capex_to_Revenue','Cash_per_Share','Current_ratio','Days_Payables_Outstanding','Days_Sales_Outstanding',\n",
    "'Days_of_Inventory_on_Hand','Debt_to_Assets','Debt_to_Equity','Dividend_Yield','EV_to_Free_cash_flow','EV_to_Operating_cash_flow','EV_to_Sales','Earnings_Yield',\n",
    "'Enterprise_Value','Enterprise_Value_over_EBITDA','Free_Cash_Flow_Yield','Free_Cash_Flow_per_Share','Graham_Net-Net','Graham_Number','Income_Quality','Intangibles_to_Total_Assets',\n",
    "'Interest_Coverage','Interest_Debt_per_Share','Inventory_Turnover','Invested_Capital','Market_Cap','Net_Current_Asset_Value','Net_Debt_to_EBITDA','Net_Income_per_Share',\n",
    "'Operating_Cash_Flow_per_Share','PB_ratio','PE_ratio','PFCF_ratio','POCF_ratio','PTB_ratio','Payables_Turnover','Payout_Ratio','Price_to_Sales_Ratio','R&D_to_Revenue',\n",
    "'ROE','ROIC','Receivables_Turnover','Return_on_Tangible_Assets','Revenue_per_Share','SG&A_to_Revenue','STK_TKR','Shareholders_Equity_per_Share','Stock-based_compensation_to_Revenue',\n",
    "'Tangible_Asset_Value','Tangible_Book_Value_per_Share','Working_Capital','Date_year']    \n",
    "\n",
    "\n",
    "saveToSQL('financial_ratio',dfdata,'replace')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to load stock profile -3\n",
    "\n",
    "import urllib.request, json\n",
    "import pandas as pd\n",
    "from pandas.io.json import json_normalize\n",
    "\n",
    "dfsym = pd.read_json (r'symbol_selected.json',orient='records')\n",
    "\n",
    "dfdata = pd.DataFrame()\n",
    "\n",
    "rowcount = 0\n",
    "companies = dfsym['symbol']\n",
    "nodatalist =[]\n",
    "url = 'https://financialmodelingprep.com/api/v3/company/profile/code'\n",
    "for x in companies:\n",
    "    print(x)\n",
    "    newurl = url.replace('code',x)\n",
    "    with urllib.request.urlopen(newurl) as url_stdata:\n",
    "        data = json.loads(url_stdata.read().decode())\n",
    "        if (data != {} ):\n",
    "            mydata = data['profile']\n",
    "            #print(mydata)\n",
    "            if (dfdata.shape[0] ==0):\n",
    "                dfdata['STK_TKR'] = \"\"\n",
    "            rowcount = dfdata.shape[0]\n",
    "            dfdata = dfdata.append(mydata,ignore_index= True)\n",
    "            currrow = rowcount+len(mydata\n",
    "            dfdata.iloc[rowcount:currrow,dfdata.columns.get_loc('STK_TKR')]=x\n",
    "        else:\n",
    "            nodatalist.append(x)\n",
    "       \n",
    "    \n",
    "print('Companies that do not have data',nodatalist)\n",
    "\n",
    "dfdata.columns = ['STK_TKR','beta','ceo','changes','changesPercentage','companyName','description','exchange','image','industry','lastDiv','mktCap','price','range','sector','volAvg','website']   \n",
    "\n",
    "\n",
    "saveToSQL('stock_profile',dfdata,'replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to load financial growth-4\n",
    "\n",
    "import urllib.request, json\n",
    "import pandas as pd\n",
    "from pandas.io.json import json_normalize\n",
    "\n",
    "dfsym = pd.read_json (r'symbol_selected.json',orient='records')\n",
    "\n",
    "dfdata = pd.DataFrame()\n",
    "\n",
    "rowcount = 0\n",
    "companies = dfsym['symbol']\n",
    "nodatalist =[]\n",
    "url = 'https://financialmodelingprep.com/api/v3/financial-statement-growth/code'\n",
    "for x in companies:\n",
    "    print(x)\n",
    "    newurl = url.replace('code',x)\n",
    "    \n",
    "    def fetch_data(url):\n",
    "        try:\n",
    "            with urllib.request.urlopen(newurl) as url_stdata:\n",
    "                data = json.loads(url_stdata.read().decode())\n",
    "                return data\n",
    "        except :\n",
    "            print (\"Failed trying again\") \n",
    "            return fetch_data(url)\n",
    "    data = fetch_data(newurl)\n",
    "    if (data != {} ):\n",
    "            mydata = data['growth']\n",
    "            #print(mydata)\n",
    "            if (dfdata.shape[0] ==0):\n",
    "                dfdata['STK_TKR'] = \"\"\n",
    "            rowcount = dfdata.shape[0]\n",
    "            #print(rowcount)\n",
    "            dfdata = dfdata.append(mydata,ignore_index= True)\n",
    "            currrow = rowcount+len(mydata)\n",
    "            #print(currrow)\n",
    "            dfdata.iloc[rowcount:currrow,dfdata.columns.get_loc('STK_TKR')]=x\n",
    "            #print(dfdata.columns)\n",
    "    else:\n",
    "        nodatalist.append(x)\n",
    "       \n",
    "    \n",
    "print('Companies that do not have data',nodatalist)\n",
    "\n",
    "dfdata.columns = ['10Y_Dividend_per_Share_Growth_per_Share','10Y_Net_Income_Growth_per_Share','10Y_Operating_CF_Growth_per_Share',\n",
    "                  '10Y_Revenue_Growth_per_Share','10Y_Shareholders_Equity_Growth_per_Share','3Y_Dividend_per_Share_Growth_per_Share',\n",
    "                  '3Y_Net_Income_Growth_per_Share','3Y_Operating_CF_Growth_per_Share','3Y_Revenue_Growth_per_Share',\n",
    "                  '3Y_Shareholders_Equity_Growth_per_Share','5Y_Dividend_per_Share_Growth_per_Share','5Y_Net_Income_Growth_per_Share',\n",
    "                  '5Y_Operating_CF_Growth_per_Share','5Y_Revenue_Growth_per_Share','5Y_Shareholders_Equity_Growth_per_Share','Asset_Growth',\n",
    "                  'Book_Value_per_Share_Growth','Debt_Growth','Dividends_per_Share_Growth','EBIT_Growth','EPS_Diluted_Growth',\n",
    "                  'EPS_Growth','Free_Cash_Flow_growth','Gross_Profit_Growth','Inventory_Growth','Net_Income_Growth',\n",
    "                  'Operating_Cash_Flow_growth','Operating_Income_Growth','R&D_Expense_Growth','Receivables_growth','SG&A_Expenses_Growth',\n",
    "                  'STK_TKR','Weighted_Average_Shares_Diluted_Growth','Weighted_Average_Shares_Growth','date_year']   \n",
    "\n",
    "saveToSQL('financial_growth',dfdata,'replace')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
